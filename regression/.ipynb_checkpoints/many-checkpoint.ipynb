{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "timeformat = \"%Y-%m-%d %H:%M:%S\"\n",
    "locations = [\"EL\", \"LB\", \"NT\", \"CH\"]\n",
    "\n",
    "data = pd.read_csv(\"../data/many/nan.csv\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.rename(columns={'EL_PM2.5':'EL_PM25', 'CH_PM2.5':'CH_PM25', 'NT_PM2.5':'NT_PM25', 'LB_PM2.5':'LB_PM25'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wind(cell, angle):\n",
    "    return math.cos(cell - angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    data['EL_PM25_' + str(i+1)] = data['EL_PM25'].shift(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    data['LB_PM25_' + str(i+1)] = data['LB_PM25'].shift(i+1)\n",
    "    data['CH_PM25_' + str(i+1)] = data['CH_PM25'].shift(i+1)\n",
    "    data['NT_PM25_' + str(i+1)] = data['NT_PM25'].shift(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['LB_wight'] = data.LB_WIND_DIREC.apply(wind, args=(18.3,))\n",
    "data['CH_wight'] = data.CH_WIND_DIREC.apply(wind, args=(130.7,))\n",
    "data['NT_wight'] = data.NT_WIND_DIREC.apply(wind, args=(275.1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['LB_relative_PM25'] = data.LB_PM25 - data.EL_PM25\n",
    "data['NT_relative_PM25'] = data.NT_PM25 - data.EL_PM25\n",
    "data['CH_relative_PM25'] = data.CH_PM25 - data.EL_PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['LB'] = data.LB_relative_PM25 * data.LB_wight\n",
    "data['CH'] = data.CH_relative_PM25 * data.CH_wight\n",
    "data['NT'] = data.NT_relative_PM25 * data.NT_wight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['target'] = data.EL_PM25.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['dlt'] = data.target - data.EL_PM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EL_AMB_TEMP', 'EL_RAINFALL', 'EL_RH', 'EL_PM25', 'EL_PM25_1', 'EL_PM25_2', 'EL_PM25_3', 'EL_PM25_4', 'EL_PM25_5', 'EL_PM25_6']\n"
     ]
    }
   ],
   "source": [
    "exclude = ['datetime', 'target']\n",
    "A_features = [f for f in data.columns if f not in exclude and \"EL\" in f and \"WIND\" not in f and \"dlt\" not in f]\n",
    "\n",
    "print A_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LB', 'CH', 'NT']\n"
     ]
    }
   ],
   "source": [
    "B_features = [\"LB\", \"CH\", \"NT\"]\n",
    "\n",
    "print B_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Season Clustering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "...\n",
    "winter = data[(data.month_12 == 1) | (data.month_1 == 1) | (data.month_2 == 1)]\n",
    "spring = data[(data.month_3 == 1) | (data.month_4 == 1) | (data.month_5 == 1)]\n",
    "summer = data[(data.month_6 == 1) | (data.month_7 == 1) | (data.month_8 == 1)]\n",
    "fall = data[(data.month_9 == 1) | (data.month_10 == 1) | (data.month_11 == 1)]\n",
    "\n",
    "season = [winter, spring, summer, fall]\n",
    "\n",
    "for each_season in season:\n",
    "    train = each_season[each_season.datetime.values < '2016-01-01 00:00:00'].dropna()\n",
    "    test = each_season[each_season.datetime.values >= '2016-01-01 00:00:00'].dropna()\n",
    "    print train.shape, test.shape\n",
    "    \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = data[data.datetime.values == '2016-07-01 00:00:00'].index[0]\n",
    "\n",
    "datatrain = data[:start]\n",
    "datatest = data[start:]\n",
    "\n",
    "column = A_features + B_features + ['target', 'dlt']\n",
    "\n",
    "train = datatrain[column].dropna()\n",
    "test = datatest[column].dropna()\n",
    "\n",
    "A_train, y_train, B_train, d_train = train[A_features], train['target'], train[B_features], train['dlt']\n",
    "A_test, y_test, B_test, d_test = test[A_features], test['target'], test[B_features], test['dlt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consume:  2.02961707115  s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning:\n",
      "\n",
      "internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A_list = list()\n",
    "B_list = list()\n",
    "C_train = pd.DataFrame(columns=['A', 'B'])\n",
    "C_test = pd.DataFrame(columns=['A', 'B'])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "A = neural_network.MLPRegressor()\n",
    "A.fit(A_train, y_train)\n",
    "\n",
    "B = linear_model.LinearRegression()\n",
    "B.fit(B_train, d_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print \"Time consume: \", end_time - start_time, ' s.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    A_predict = A.predict([A_test.iloc[i]])\n",
    "    B_predict = B.predict([B_test.iloc[i]])\n",
    "    A_list.append(A_predict)\n",
    "    B_predict = B_predict + A_test.EL_PM25.iloc[i]\n",
    "    B_list.append(B_predict)\n",
    "    C_test = C_test.append(pd.DataFrame([[A_predict,B_predict]],columns=['A','B']), ignore_index=True)\n",
    "\n",
    "for j in range(len(y_train)):\n",
    "    C_train = C_train.append(pd.DataFrame([[A.predict([A_train.iloc[j]]),\n",
    "                                            B.predict([B_train.iloc[j]]) + A_train.EL_PM25.iloc[j]]],\n",
    "                           columns=['A','B']), ignore_index=True)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "A_rmse = sqrt(mean_squared_error(A_list, y_test))\n",
    "B_rmse = sqrt(mean_squared_error(B_list, y_test))\n",
    "\n",
    "print \"Time consume: \", end_time - start_time, ' s.'\n",
    "print \"A rmse: \", A_rmse\n",
    "print \"B rmse: \", B_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "C = GradientBoostingRegressor()\n",
    "C.fit(C_train, y_train)\n",
    "C_list = C.predict(C_test)\n",
    "C_rmse = sqrt(mean_squared_error(C_list, y_test))\n",
    "    \n",
    "end_time = time.time()\n",
    "print \"Time consume: \", end_time - start_time, ' s.'\n",
    "print \"C rmse: \", C_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
